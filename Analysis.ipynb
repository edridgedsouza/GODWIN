{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T03:09:52.234858Z",
     "start_time": "2021-03-24T03:09:51.715860Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Dec 12 22:27:52 2014\n",
    "\n",
    "@author: LukasHalim\n",
    "Forked by @edridgedsouza\n",
    "\n",
    "2) For each post, determine earliest failure\n",
    "- Sort the comments for each post in ascending order\n",
    "- Create a variable for the comment number within each post\n",
    "- In cases where there is a failure, identify the first failing comment\n",
    "- In cases where there is not a failure, identify the final comment for the post\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import csv\n",
    "\n",
    "import sqlite3\n",
    "from godwin import Scraper, Database\n",
    "\n",
    "db = Database('Godwin.db')\n",
    "# db.reset_db()\n",
    "s = Scraper(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-24T03:23:42.133Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping from /r/politicalcompassmemes: 100it [00:07, 14.02it/s]\n",
      "Scraped 1 of 200 subreddits\n",
      "Scraping from /r/europe: 100it [00:08, 12.12it/s]\n",
      "Scraped 2 of 200 subreddits\n",
      "Scraping from /r/teenagers: 100it [00:15,  6.54it/s]\n",
      "Scraped 3 of 200 subreddits\n",
      "Scraping from /r/witcher: 100it [00:07, 13.05it/s]\n",
      "Scraped 4 of 200 subreddits\n",
      "Scraping from /r/mechanicalkeyboards: 100it [00:06, 14.46it/s]\n",
      "Scraped 5 of 200 subreddits\n",
      "Scraping from /r/instagram: 100it [00:04, 20.70it/s]\n",
      "Scraped 6 of 200 subreddits\n",
      "Scraping from /r/moviedetails: 100it [00:04, 23.45it/s]\n",
      "Scraped 7 of 200 subreddits\n",
      "Scraping from /r/fo76: 100it [00:07, 14.20it/s]\n",
      "Scraped 8 of 200 subreddits\n",
      "Scraping from /r/whatcouldgowrong: 100it [00:10,  9.40it/s]\n",
      "Scraped 9 of 200 subreddits\n",
      "Scraping from /r/totalwar: 100it [00:05, 17.31it/s]\n",
      "Scraped 10 of 200 subreddits\n",
      "Scraping from /r/fortnitebr: 100it [00:06, 16.04it/s]\n",
      "Scraped 11 of 200 subreddits\n",
      "Scraping from /r/cringe: 100it [00:06, 16.54it/s]\n",
      "Scraped 12 of 200 subreddits\n",
      "Scraping from /r/barstoolsports: 100it [00:06, 15.96it/s]\n",
      "Scraped 13 of 200 subreddits\n",
      "Scraping from /r/cringetopia: 0it [00:00, ?it/s]\n",
      "Scraped 14 of 200 subreddits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit cringetopia forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping from /r/facepalm: 100it [00:08, 12.17it/s]\n",
      "Scraped 15 of 200 subreddits\n",
      "Scraping from /r/books: 100it [00:06, 14.69it/s]\n",
      "Scraped 16 of 200 subreddits\n",
      "Scraping from /r/pokemon: 100it [00:07, 12.61it/s]\n",
      "Scraped 17 of 200 subreddits\n",
      "Scraping from /r/apexlegends: 100it [00:02, 43.66it/s]\n",
      "Scraped 18 of 200 subreddits\n",
      "Scraping from /r/dndnext: 100it [00:01, 55.90it/s]\n",
      "Scraped 19 of 200 subreddits\n",
      "Scraping from /r/trashy: 0it [00:00, ?it/s]\n",
      "Scraped 20 of 200 subreddits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit trashy forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping from /r/sysadmin: 100it [00:01, 54.17it/s]\n",
      "Scraped 21 of 200 subreddits\n",
      "Scraping from /r/insanepeoplefacebook: 100it [00:01, 59.23it/s]\n",
      "Scraped 22 of 200 subreddits\n"
     ]
    }
   ],
   "source": [
    "s.scrape_top_subreddits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comments_df = pd.read_sql(\"select * from comment\",conn)\n",
    "g = comments_df.groupby('post_id')\n",
    "#Sort the comments for each post in ascending order\n",
    "comments_df['RN'] = g['comment_created'].rank(method='first')\n",
    "#Create a variable for the comment number within each post\n",
    "comments_with_nazi_df = comments_df[comments_df.nazi_in_comment == 1]\n",
    "#Identify posts where there is a mention of Nazi\n",
    "nazi_posts = comments_with_nazi_df['post_id'].unique()\n",
    "\n",
    "#In cases where there is a comparison with Nazis or Hitler, identify the first comment \n",
    "#where the comparison is made\n",
    "mins = comments_with_nazi_df.groupby('post_id')['RN'].idxmin()\n",
    "first_nazi_comment = comments_with_nazi_df.loc[mins]\n",
    "\n",
    "right_censored_posts = comments_df[comments_df.post_id.isin(nazi_posts) == False]\n",
    "maxes = right_censored_posts.groupby('post_id')['RN'].idxmax()\n",
    "final_comment = right_censored_posts.loc[maxes]\n",
    "\n",
    "#combine the censored posts with those where a comparison is made\n",
    "concatenated = pd.concat([first_nazi_comment,final_comment])\n",
    "\n",
    "T = concatenated['RN']\n",
    "E = concatenated['nazi_in_comment']\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(T, event_observed=E)\n",
    "kmf.plot()\n",
    "\n",
    "plt.xlim(0,2000);\n",
    "plt.title(\"Reddit Post Lifespan Prior to Mention of Nazi or Hitler\");\n",
    "plt.xlabel(\"Comments\")\n",
    "plt.ylabel(\"Fraciton of Posts Without Mention of Hitler or Nazis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
